window.search = {"searchoptions":{"bool":"OR","expand":true,"limit_results":30,"teaser_word_count":30,"fields":{"title":{"boost":2},"body":{"boost":1},"breadcrumbs":{"boost":1}}},"index":{"fields":["title","body","breadcrumbs"],"pipeline":["trimmer","stopWordFilter","stemmer"],"ref":"id","version":"0.9.5","index":{"breadcrumbs":{"root":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}}},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}}}},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}},"e":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":6,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952}}}}}},"v":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}}},"o":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"f":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.7320508075688773}}}}}},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}},"t":{"df":2,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.4142135623730952}}}}}},"s":{"df":0,"docs":{},"s":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"0":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}},"~":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"m":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-17-embeddings.html#embeddings":{"tf":1.4142135623730952}}}}},"p":{"df":0,"docs":{},"i":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"n":{"df":0,"docs":{},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.4142135623730952}}}}},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":2,"docs":{"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.7320508075688773}}}},"a":{"df":0,"docs":{},"p":{"df":0,"docs":{},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"l":{"df":0,"docs":{},"e":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}}}}},"r":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}},"x":{"df":6,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.4142135623730952}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":6,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.7320508075688773},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952}}}}}}},"d":{"df":0,"docs":{},"g":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":0,"docs":{},"c":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}},"f":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":4,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952}}}}}}}},"e":{"df":0,"docs":{},"g":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"/":{"df":0,"docs":{},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}}}}}},"r":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}}}}},"t":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.4142135623730952}}}}},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},".":{"df":0,"docs":{},"i":{"df":0,"docs":{},".":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"z":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}},"m":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":13,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.7320508075688773},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952}}}}},"r":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.4142135623730952}}}}}},"l":{"df":38,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-17-embeddings.html#embeddings":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#generalization":{"tf":1.0},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"ml-concepts/ch01-01-framing.html#framing":{"tf":1.0},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0},"ml-concepts/ch01-12-classification.html#classification":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-08-representation.html#representation":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.7320508075688773},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-07-validation.html#validation":{"tf":1.0}}},"a":{"df":0,"docs":{},"k":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.7320508075688773}}}}},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":4,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}}}}},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}},"m":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}},"i":{"df":0,"docs":{},"z":{"df":0,"docs":{},"e":{"df":0,"docs":{},"(":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"(":{"df":0,"docs":{},"d":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":0,"docs":{},"|":{"df":0,"docs":{},"m":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"1":{"df":6,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}},"0":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}},"0":{"df":0,"docs":{},"0":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}},"w":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}},"x":{"df":0,"docs":{},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}},"\\":{"df":0,"docs":{},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"{":{"df":0,"docs":{},"x":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}}}}}}},"e":{"df":0,"docs":{},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"h":{"df":0,"docs":{},"t":{"df":8,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.7320508075688773},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}}},"n":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}},"n":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.4142135623730952}}}}}}}}},"i":{"df":0,"docs":{},"s":{"df":2,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.4142135623730952}}}}},"u":{"df":0,"docs":{},"m":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}}},"a":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}}},"w":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}},"t":{"df":3,"docs":{"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.4142135623730952}}},"u":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":3,"docs":{"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.4142135623730952}}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0}}}}}}},"b":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952}},"u":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952}}}},"f":{"df":0,"docs":{},"f":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0}}}}}}}},"i":{"df":0,"docs":{},"a":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.4142135623730952}},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}}}},"a":{"df":0,"docs":{},"d":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}},"t":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.8284271247461905},"appendix/a-cheat-sheet.html#terminology":{"tf":1.7320508075688773}}}}}}},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}},"i":{"df":0,"docs":{},"n":{"df":9,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.7320508075688773},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.7320508075688773},"appendix/a-cheat-sheet.html#terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.4142135623730952},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"k":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.7320508075688773}},"(":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":3,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.4142135623730952},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.7320508075688773},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.4142135623730952}}}},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"w":{"df":3,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.6457513110645909},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":2.0}}}}}}}}}},"r":{"df":0,"docs":{},"m":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"g":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952}}}}}}}}}}},"f":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.4142135623730952}},".":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"y":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}}}},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"m":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}}}}}}}},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.4142135623730952}}}}}},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"p":{"df":0,"docs":{},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"x":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}},"a":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.4142135623730952}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"x":{"df":6,"docs":{"appendix/appendix.html#appendix":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.0}}}}}}}},"i":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.7320508075688773}}}},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"q":{"df":0,"docs":{},"u":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.4142135623730952}}}}}},"d":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.7320508075688773}}}}}},"c":{"df":0,"docs":{},"p":{"df":0,"docs":{},"u":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"o":{"df":0,"docs":{},"u":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}}},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"e":{"df":0,"docs":{},"x":{"df":2,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}},"t":{"df":2,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0}}},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"y":{"df":0,"docs":{},"(":{"df":0,"docs":{},"m":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}}}}}}}}}}},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"m":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"n":{"df":0,"docs":{},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"g":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}}},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"u":{"df":2,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}}},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":37,"docs":{"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0},"ml-concepts/ch01-12-classification.html#classification":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.0},"ml-concepts/ch01-07-validation.html#validation":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-01-framing.html#framing":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#generalization":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-17-embeddings.html#embeddings":{"tf":1.0},"ml-concepts/ch01-08-representation.html#representation":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0}}}}}}}},"h":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":0,"docs":{},"g":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.4142135623730952}}}}}},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.4142135623730952}}}}},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":3,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.4142135623730952}},"i":{"df":0,"docs":{},"f":{"df":3,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-12-classification.html#classification":{"tf":1.4142135623730952}}}}}}}},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":3,"docs":{"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.4142135623730952},"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.4142135623730952},"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}}}}},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"c":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.4142135623730952}}},"d":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.4142135623730952}}}}}}},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}}},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"v":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"w":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}}},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"c":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}}},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"b":{"df":0,"docs":{},"u":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.7320508075688773}}}}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}}},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"n":{"df":0,"docs":{},"'":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":9,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}}},"k":{"df":0,"docs":{},"e":{"df":0,"docs":{},"y":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"u":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952}}}}}}},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"s":{"df":0,"docs":{},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.4142135623730952}}}}}},"q":{"df":0,"docs":{},"u":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952}}}}}},"c":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"e":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":2.0}},"v":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"u":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}}}}}},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"b":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}}},"y":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.0}}}}}}}},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"i":{"df":0,"docs":{},"f":{"df":1,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952}}}}}},"a":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.4142135623730952}}}}}}}},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952}}}}}},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"z":{"df":0,"docs":{},"e":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.4142135623730952}}}}}}}},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"g":{"df":2,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"p":{"df":3,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}},"d":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"v":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.0}}}}}}}}},"e":{"df":0,"docs":{},"t":{"df":4,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":2.23606797749979},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.4142135623730952},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952}}},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"u":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"v":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":2,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"b":{"df":0,"docs":{},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0}}}}}}}},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-01-framing.html#framing":{"tf":1.4142135623730952}}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"u":{"df":0,"docs":{},"r":{"df":9,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":3.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":2.449489742783178},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.7320508075688773},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":2.0},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}}}}}},"i":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.4142135623730952}}}}}},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}},"n":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}}}}}},"l":{"df":0,"docs":{},"e":{"df":0,"docs":{},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.0}}}}},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"n":{"df":6,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":2.6457513110645909},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.7320508075688773},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}}}},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.7320508075688773}}}}}},"b":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}},"2":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.7320508075688773}}},"_":{"df":0,"docs":{},"2":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"o":{"df":0,"docs":{},"w":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"g":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.4142135623730952}}}}}},"s":{"df":0,"docs":{},"s":{"df":6,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":2.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":2.8284271247461905}}}}},"a":{"df":0,"docs":{},"b":{"df":0,"docs":{},"l":{"df":1,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}},"e":{"df":0,"docs":{},"l":{"df":6,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0}}}}},"m":{"df":0,"docs":{},"b":{"df":0,"docs":{},"d":{"df":0,"docs":{},"a":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":2.449489742783178}}}}}}}},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.4142135623730952}}}}},"t":{"df":0,"docs":{},"t":{"df":0,"docs":{},"p":{"df":0,"docs":{},"s":{"df":0,"docs":{},":":{"df":0,"docs":{},"/":{"df":0,"docs":{},"/":{"df":0,"docs":{},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"u":{"df":0,"docs":{},"b":{"df":0,"docs":{},".":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":0,"docs":{},"/":{"df":0,"docs":{},"j":{"df":0,"docs":{},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":0,"docs":{},"/":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"df":0,"docs":{},"/":{"df":0,"docs":{},"/":{"df":0,"docs":{},"j":{"df":0,"docs":{},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":0,"docs":{},".":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":0,"docs":{},"/":{"df":0,"docs":{},"2":{"df":0,"docs":{},"0":{"df":0,"docs":{},"1":{"df":0,"docs":{},"6":{"df":0,"docs":{},"/":{"df":0,"docs":{},"0":{"df":0,"docs":{},"5":{"df":0,"docs":{},"/":{"df":0,"docs":{},"2":{"df":0,"docs":{},"3":{"df":0,"docs":{},"/":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"o":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}},"y":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"p":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}}}}}}}}}}}},"o":{"df":0,"docs":{},"n":{"df":2,"docs":{"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}},"o":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":3,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.7320508075688773}}}}}}}},"u":{"df":0,"docs":{},"t":{"df":0,"docs":{},"p":{"df":0,"docs":{},"u":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952}}}}},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}}}}},"p":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.4142135623730952}}}}},"e":{"df":0,"docs":{},"r":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.4142135623730952}}}}}},"g":{"df":0,"docs":{},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"g":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}},"d":{"df":2,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.4142135623730952}}}}},"p":{"df":0,"docs":{},"u":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#generalization":{"tf":1.4142135623730952}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"p":{"df":0,"docs":{},"h":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.23606797749979},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952}}}},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":5,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":2.23606797749979},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.0}}}}}}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":5,"docs":{"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}},"{":{"df":0,"docs":{},"i":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952}}}}}},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"u":{"df":5,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.7320508075688773},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":2.449489742783178},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952}}},"i":{"df":0,"docs":{},"d":{"df":2,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.7320508075688773},"ml-concepts/ch01-07-validation.html#validation":{"tf":1.4142135623730952}}}}}},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"a":{"df":0,"docs":{},"b":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}}}}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"w":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}},"t":{"df":0,"docs":{},"e":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":2.449489742783178},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"k":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"u":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}}}}}}},"g":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.4142135623730952},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.4142135623730952},"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.7320508075688773}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":6,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.4142135623730952}}}}}}},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.4142135623730952}}}}},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#representation":{"tf":1.4142135623730952}}}}}}}}}}},"x":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}},"y":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.7320508075688773}}},"j":{"df":0,"docs":{},"v":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"body":{"root":{"df":0,"docs":{},"x":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}},"1":{"df":6,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.4142135623730952}},"0":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}},"0":{"df":0,"docs":{},"0":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}},"n":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}},"u":{"df":0,"docs":{},"m":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}}},"t":{"df":3,"docs":{"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0}}},"w":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0}}}}},"u":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":3,"docs":{"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0}}}}}}},"o":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0}}}},"d":{"df":0,"docs":{},"e":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"n":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.0}}}}}}}}}},"a":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":6,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952}}}}}},"v":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"o":{"df":0,"docs":{},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"r":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0}}}},"t":{"df":2,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.7320508075688773}}}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"f":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}}},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":0,"docs":{},"g":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.0}}}}}},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":3,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}},"i":{"df":0,"docs":{},"f":{"df":3,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-12-classification.html#classification":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}}}},"o":{"df":0,"docs":{},"m":{"df":0,"docs":{},"m":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"e":{"df":0,"docs":{},"x":{"df":2,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}},"t":{"df":2,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"y":{"df":0,"docs":{},"(":{"df":0,"docs":{},"m":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}}}}}}}}}}},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"u":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}}},"n":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}}}},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"u":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"g":{"df":3,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}}},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":3,"docs":{"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.0}}}}}},"p":{"df":0,"docs":{},"u":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"q":{"df":0,"docs":{},"u":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0}}}}}},"d":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.7320508075688773}}}}}},"e":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"i":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-17-embeddings.html#embeddings":{"tf":1.0}}}}}},"d":{"df":0,"docs":{},"g":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"l":{"df":0,"docs":{},"e":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}}}}},"r":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952}}}}}},"x":{"df":6,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.4142135623730952}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":6,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.7320508075688773}}}}}}},"n":{"df":0,"docs":{},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}},"c":{"df":0,"docs":{},"a":{"df":0,"docs":{},"p":{"df":0,"docs":{},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"o":{"df":0,"docs":{},"d":{"df":2,"docs":{"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.7320508075688773}}}}}}},"y":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.7320508075688773}}},"h":{"df":0,"docs":{},"t":{"df":0,"docs":{},"t":{"df":0,"docs":{},"p":{"df":0,"docs":{},":":{"df":0,"docs":{},"/":{"df":0,"docs":{},"/":{"df":0,"docs":{},"j":{"df":0,"docs":{},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":0,"docs":{},".":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":0,"docs":{},"/":{"df":0,"docs":{},"2":{"df":0,"docs":{},"0":{"df":0,"docs":{},"1":{"df":0,"docs":{},"6":{"df":0,"docs":{},"/":{"df":0,"docs":{},"0":{"df":0,"docs":{},"5":{"df":0,"docs":{},"/":{"df":0,"docs":{},"2":{"df":0,"docs":{},"3":{"df":0,"docs":{},"/":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"s":{"df":0,"docs":{},":":{"df":0,"docs":{},"/":{"df":0,"docs":{},"/":{"df":0,"docs":{},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"u":{"df":0,"docs":{},"b":{"df":0,"docs":{},".":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":0,"docs":{},"/":{"df":0,"docs":{},"j":{"df":0,"docs":{},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":0,"docs":{},"/":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"y":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"p":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}}}}}}}}}}},"o":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.4142135623730952}}}}}},"z":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}},"u":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952}}}}}}},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":6,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":2.6457513110645909},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":2.0},"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0}}}},"w":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"g":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0}}}}}}},"_":{"df":0,"docs":{},"2":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"n":{"df":6,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":2.449489742783178},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.0}}}}}},"2":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.4142135623730952}}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"b":{"df":0,"docs":{},"d":{"df":0,"docs":{},"a":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":2.23606797749979}}}}}},"b":{"df":0,"docs":{},"l":{"df":1,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}},"e":{"df":0,"docs":{},"l":{"df":6,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.7320508075688773}}}}}},"i":{"df":0,"docs":{},"b":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952}}}}}}}},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0}}}}}}},"g":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"z":{"df":0,"docs":{},"e":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952}}}}},"u":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"v":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":2,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"b":{"df":0,"docs":{},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0}}}}}}},"p":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0}}}}}}},"c":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"i":{"df":0,"docs":{},"f":{"df":1,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}}},"y":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.0}}}}}}}},"e":{"df":0,"docs":{},"t":{"df":4,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":2.23606797749979},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952}}},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}},"c":{"df":0,"docs":{},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"b":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}},"e":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":2.0}},"v":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"u":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}}}}}},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}}},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.0}}}}}},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"g":{"df":2,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"d":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"v":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.7320508075688773}}}}}}}},"e":{"df":0,"docs":{},"p":{"df":3,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}}},"q":{"df":0,"docs":{},"u":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952}}}}}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"m":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"k":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.7320508075688773}}}}},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":4,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}},"s":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":13,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.7320508075688773},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952},"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0}}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}},"m":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}},"i":{"df":0,"docs":{},"z":{"df":0,"docs":{},"e":{"df":0,"docs":{},"(":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"(":{"df":0,"docs":{},"d":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":0,"docs":{},"|":{"df":0,"docs":{},"m":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}}}}}}}}}}}}}}}}}}}}}},"l":{"df":6,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0}}}},"i":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"t":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}},".":{"df":0,"docs":{},"i":{"df":0,"docs":{},".":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":0,"docs":{},"c":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}},"t":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}},"g":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"/":{"df":0,"docs":{},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}}}}}}},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0}}}}}}}}},"f":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":4,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.4142135623730952}}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"u":{"df":0,"docs":{},"r":{"df":9,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":3.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.7320508075688773},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":2.23606797749979},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.7320508075688773}}}}}}},"i":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-01-framing.html#framing":{"tf":1.0}}}}}},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}},"n":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}}}}}},"k":{"df":0,"docs":{},"e":{"df":0,"docs":{},"y":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"v":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"u":{"df":5,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":2.449489742783178},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.7320508075688773}}},"i":{"df":0,"docs":{},"d":{"df":2,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.7320508075688773},"ml-concepts/ch01-07-validation.html#validation":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"{":{"df":0,"docs":{},"i":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952}}}},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":5,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.0}}}}}}},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"a":{"df":0,"docs":{},"b":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}}}}}}}}},"0":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}},"~":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0}}}}},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#representation":{"tf":1.0}}}}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}}}}}}},"g":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.4142135623730952},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":6,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}}}}},"u":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"e":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":2.23606797749979},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.4142135623730952}}}},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"w":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"k":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}},"w":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}},"x":{"df":0,"docs":{},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"h":{"df":0,"docs":{},"t":{"df":8,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.7320508075688773},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}},"\\":{"df":0,"docs":{},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"{":{"df":0,"docs":{},"x":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}}}}}}}},"d":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"w":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}}},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"v":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}}},"s":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":3,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.7320508075688773}}},"d":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.0}}}}},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":9,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"b":{"df":0,"docs":{},"u":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.7320508075688773}}}}}}}},"c":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"n":{"df":0,"docs":{},"'":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}}},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"p":{"df":0,"docs":{},"h":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.23606797749979}}}},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":5,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.7320508075688773},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":2.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952}}}}}}}}},"p":{"df":0,"docs":{},"u":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#generalization":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"g":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}},"d":{"df":2,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.4142135623730952}}}},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0}}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":3,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}}}}},"u":{"df":0,"docs":{},"t":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}}},"p":{"df":0,"docs":{},"u":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952}}}}}}},"n":{"df":2,"docs":{"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.0},"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}},"o":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"m":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}}}}},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"p":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"x":{"df":1,"docs":{"appendix/appendix.html#appendix":{"tf":1.0}}}}}}},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"a":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}},"x":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}},"i":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.7320508075688773}}}},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0}}}}}}},"t":{"df":0,"docs":{},"f":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0}},".":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"y":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"w":{"df":3,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.6457513110645909},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.7320508075688773},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952}}}}}}}}}},"r":{"df":0,"docs":{},"m":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"g":{"df":3,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}}}}}},"s":{"df":0,"docs":{},"t":{"df":3,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.4142135623730952},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.7320508075688773}}}}},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"k":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.4142135623730952}},"(":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}},"i":{"df":0,"docs":{},"n":{"df":9,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.7320508075688773},"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952}}}}}}},"b":{"df":2,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952}},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0}}}}}}}},"i":{"df":0,"docs":{},"a":{"df":2,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.4142135623730952}},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}}}},"u":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952}}}},"f":{"df":0,"docs":{},"f":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"a":{"df":0,"docs":{},"d":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}},"t":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.8284271247461905}}}}}}},"j":{"df":0,"docs":{},"v":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"title":{"root":{"df":0,"docs":{},"v":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-07-validation.html#validation":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.0}}}}}}}},"t":{"df":0,"docs":{},"f":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0}}},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"k":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"m":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"g":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}}}}}},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0}}}},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"w":{"df":1,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":3,"docs":{"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":3,"docs":{"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0}}}}}}},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0}}}}},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#representation":{"tf":1.0}}}}}}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"e":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0}}}}}},"l":{"df":0,"docs":{},"2":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"tf":1.0}}},"o":{"df":0,"docs":{},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0}}}}}},"s":{"df":0,"docs":{},"s":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"b":{"df":0,"docs":{},"d":{"df":0,"docs":{},"a":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"tf":1.0}}}}}}},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"n":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.0}}}}},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0}}}}}},"m":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-17-embeddings.html#embeddings":{"tf":1.0}}}}}}},"g":{"df":0,"docs":{},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0}}}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#generalization":{"tf":1.0}}}}}}},"q":{"df":0,"docs":{},"u":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0}}}}}}}}},"m":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0}}}}}},"l":{"df":4,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}},"d":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.0}}}}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":2,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0}}}}}},"c":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0}},"i":{"df":0,"docs":{},"f":{"df":1,"docs":{"ml-concepts/ch01-12-classification.html#classification":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#cleaning-data":{"tf":1.0}}}}}},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"n":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}}}}}},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":2,"docs":{"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.0}}}}}}},"a":{"df":0,"docs":{},"p":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"x":{"df":1,"docs":{"appendix/appendix.html#appendix":{"tf":1.0}}}}}}},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"a":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}}}}}},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0}}}}}}},"p":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"tf":1.0}}}}}}}}}},"e":{"df":0,"docs":{},"t":{"df":3,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0}}},"u":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":3,"docs":{"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0}}}}}}}},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}},"n":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0}}}}}}}}}}},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.0}}},"p":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0}}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}}},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}}}},"e":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0}}}}},"u":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"v":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":1,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}}}}},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.0}}}}}},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"i":{"df":0,"docs":{},"f":{"df":1,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0}}}}}}}},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0}}}},"i":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0}}}}}}}}},"f":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-01-framing.html#framing":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"u":{"df":0,"docs":{},"r":{"df":3,"docs":{"ml-concepts/ch01-08-representation.html#feature-engineering":{"tf":1.0},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0}}}}}}},"i":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0}}}}}}},"h":{"df":0,"docs":{},"o":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"tf":1.0}}}}}}}},"documentStore":{"save":true,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"id":"ml-concepts/ch01-03-reducing-loss.html#learning-rate","body":"learning rate (step size): weight를 갱신할 때 gradient에 곱해주는 scalar값 learning rate가 너무 작으면 모델이 수렴하기까지 걸리는 시간이 길어짐 learning rate가 너무 크면 모델이 수렴하지 않거나 발산할 수 있음 hyperparameter: machine learning algorithm을 최적화 하기 위해 프로그래머가 조작하는 값 ex) learning rate","breadcrumbs":"ML Concepts » Learning Rate","title":"Learning Rate"},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"title":"An Iterative Approach","body":"parameter: model의 변수 ex) weight convergence: training이 진행되면서 loss가 고정되거나 극단적으로 느리게 변하는 상태 모델은 다음과 같은 반복적인 계산을 통해 학습된다 parameter 초기화 prediction 생성 (inference) loss 계산 parameter 갱신 1번으로","id":"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach","breadcrumbs":"ML Concepts » An Iterative Approach"},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"breadcrumbs":"ML Concepts » Optimizing Learning Rate","body":"최적의 learning rate는 data와 algorithm의 특성에 따라 다름","title":"Optimizing Learning Rate","id":"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate"},"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"breadcrumbs":"ML Concepts » First Steps with TF","title":"First Steps with TF","body":"","id":"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf"},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"breadcrumbs":"ML Concepts » Introduction to Neural Nets","title":"Introduction to Neural Nets","id":"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets","body":""},"ml-concepts/ch01-01-framing.html#framing":{"id":"ml-concepts/ch01-01-framing.html#framing","body":"","breadcrumbs":"ML Concepts » Framing","title":"Framing"},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"title":"Gradient Descent","id":"ml-concepts/ch01-03-reducing-loss.html#gradient-descent","breadcrumbs":"ML Concepts » Gradient Descent","body":"linear regression에서 weight 와 loss의 관계를 좌표평면에 그려보면 밥그릇 모양이 그려지는데, 경사를 따라 내려가면서 loss를 최소화하는 weight를 찾는 방법 gradient: vector of partial derivatives vector이르모 방향과 정량적인 값을 가짐 gradient는 항상 loss function의 가장 가파른 곳을 향한다 loss를 줄이기 위해 gradient의 반대 방향으로 weight를 갱신해야 함"},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"breadcrumbs":"ML Concepts","title":"ML Concepts","body":"이 노트는 Google의 Machine Learning Crash Course 를 공부하며 정리한 내용을 담고 있습니다.","id":"ml-concepts/ch00-00-ml-concepts.html#ml-concepts"},"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"breadcrumbs":"ML Concepts » Crossing One-Hot Vectors","title":"Crossing One-Hot Vectors","id":"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors","body":"논리곱처럼 쓸 수 있음"},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"id":"ml-concepts/ch01-03-reducing-loss.html#reducing-loss","body":"","breadcrumbs":"ML Concepts » Reducing Loss","title":"Reducing Loss"},"appendix/a-cheat-sheet.html#supervised-learning":{"body":"labled example로 model을 학습시킴 Regression Continuous value를 예측 Output이 연속적인 값 Classification Discrete value를 예측 Output이 class","breadcrumbs":"Appendix » Supervised learning","title":"Supervised learning","id":"appendix/a-cheat-sheet.html#supervised-learning"},"ml-concepts/ch01-12-classification.html#classification":{"breadcrumbs":"ML Concepts » Classification","body":"","id":"ml-concepts/ch01-12-classification.html#classification","title":"Classification"},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"body":"","breadcrumbs":"ML Concepts » Regularization: Sparsity","id":"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity","title":"Regularization: Sparsity"},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"breadcrumbs":"Introduction to ML","title":"Introduction to ML","id":"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml","body":"기계 학습을 배우면 개발 시간을 줄일 수 있다. (항상 그렇진 않음) 잘못 된 예 http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/ https://github.com/joelgrus/fizz-buzz-tensorflow/ 하나의 모델로 데이터만 바꿔서 다른 프로그램을 만들 수 있다. ex) 기계 번역 규칙 기반으로 해결할 수 없는 문제를 해결할 수 있다. ex) 고양이 사진 분류"},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"title":"Terminology: Tensorflow specific","body":"graph: tensorflow에서 계산 과정은 graph로 표현됨 nodes: operations edges: passing the result of an operation (directed) tensor: tensorflow의 기본 자료 구조 (N차원 자료 구조)","id":"appendix/a-cheat-sheet.html#terminology-tensorflow-specific","breadcrumbs":"Appendix » Terminology: Tensorflow specific"},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"body":"","breadcrumbs":"ML Concepts » Feature Crosses","title":"Feature Crosses","id":"ml-concepts/ch01-09-feature-crosses.html#feature-crosses"},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"body":"","id":"ml-concepts/ch01-11-logistic-regression.html#logistic-regression","title":"Logistic Regression","breadcrumbs":"ML Concepts » Logistic Regression"},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"body":"","breadcrumbs":"ML Concepts » Multi-class Neural Nets","id":"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets","title":"Multi-class Neural Nets"},"ml-concepts/ch01-08-representation.html#representation":{"breadcrumbs":"ML Concepts » Representation","id":"ml-concepts/ch01-08-representation.html#representation","body":"","title":"Representation"},"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"id":"ml-concepts/ch01-10-regularization-simplicity.html#lambda","breadcrumbs":"ML Concepts » Lambda","title":"Lambda","body":"\\[ minimize(Loss(Data|Model) + \\lambda \\space complexity(Model)) \\] complextity를 얼마나 반영할 것인가? \\( \\lambda \\)가 너무 높으면? model이 단순해짐 underfitting \\( \\lambda \\)가 너무 낮으면? model이 복잡해짐 overfitting 이상적인 \\( \\lambda \\)는? data-dependent"},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"breadcrumbs":"ML Concepts » Training and Loss","id":"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss","title":"Training and Loss","body":"training: empirical risk minimization examples를 통해 loss를 최소화 하는 model을 찾는 과정 error: label과 prediction의 차이 signed loss: bad prediction에 대한 penalty unsigned loss function: loss를 계산하기 위한 함수 ex) squared loss(\\( L_2 \\) loss), mean square error (MSE)"},"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"breadcrumbs":"ML Concepts » Descending into ML","title":"Descending into ML","body":"","id":"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml"},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"body":"linear relationship: \\( y' = b + w_1x_1 \\) \\( y' \\): predicted label \\( b \\): bias (y-intercept) \\( w_1 \\): weight of feature 1 \\( x_1 \\): feature inference \\( \\approx \\) predict","title":"Linear Regression","id":"ml-concepts/ch01-02-descending-into-ml.html#linear-regression","breadcrumbs":"ML Concepts » Linear Regression"},"appendix/a-cheat-sheet.html#terminology":{"breadcrumbs":"Appendix » Terminology","body":"label: 예측할 대상 feature: 입력 변수 prediction: 예측값 example: instance of data (labeled, unlabeled) model: feature와 label 사이의 관계를 정의함 training: model을 만들거나 학습시키는 과정 inference: trained model에 unlabeled example을 입력으로 주어 prediction을 얻는 과정 error: label과 prediction의 차이 loss: bad prediction에 대한 penalty loss function: loss를 계산하기 위한 함수 parameter: model의 변수 convergence: training이 진행되면서 loss가 고정되거나 극단적으로 느리게 변하는 상태 gradient: vector of partial derivatives learning rate (step size): weight를 갱신할 때 gradient에 곱해주는 scalar값 hyperparameter: machine learning algorithm을 최적화 하기 위해 프로그래머가 조작하는 값 batch: 1번의 iteration에 사용되는 examples 집합 batch size: batch안의 examples 수","id":"appendix/a-cheat-sheet.html#terminology","title":"Terminology"},"ml-concepts/ch01-07-validation.html#validation":{"title":"Validation","breadcrumbs":"ML Concepts » Validation","body":"","id":"ml-concepts/ch01-07-validation.html#validation"},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"body":"","title":"Training Neural Nets","id":"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets","breadcrumbs":"ML Concepts » Training Neural Nets"},"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"body":"","title":"Regularization: Simplicity","breadcrumbs":"ML Concepts » Regularization: Simplicity","id":"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity"},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"id":"ml-concepts/ch01-04-first-steps-with-th.html#toolkit","title":"Toolkit","breadcrumbs":"ML Concepts » Toolkit","body":"tensorflow toolkit 계층 구조 Toolkit(s) Description Estimator High-level, OOP API tf.layers / tf.losses / tf.metrics Libraries for common model components Tensorflow Lower-level APIs 처음엔 high-level API를 사용하고, 모델을 더 유연하게 확장하고 싶을 때 low-level을 사용 Tensorflow는 graph protocol buffer와 (distributed) graph를 실행하기 위한 runtime으로 구성됨 JVM이 다양한 platform에서 동작하듯이 tensorflow로 CPU와 GPU에서 동작함 tf.estimator: tensorflow graph 생성과 session 실행을 encapsulate한 모듈 graph: tensorflow에서 계산 과정은 graph로 표현됨 nodes: operations edges: passing the result of an operation (directed) tensor: tensorflow의 기본 자료 구조 (N차원 자료 구조) scalars, vectors, matrices integer, floating-point, string"},"ml-concepts/ch01-01-framing.html#ml-terminology":{"title":"ML Terminology","body":"label: 예측할 대상. feature: 입력 변수. example: instance of data (labeled, unlabeled) model: feature와 label 사이의 관계를 정의함 training: model을 만들거나 학습시키는 과정 inference: trained model에 unlabeled example을 입력으로 주어 prediction을 얻는 과정 regression continuous value를 예측 output이 연속적인 값 ex) 판교의 집값은 얼마인가? classification discrete value를 예측 output이 class ex) 이 동물은 고양이인가?","breadcrumbs":"ML Concepts » ML Terminology","id":"ml-concepts/ch01-01-framing.html#ml-terminology"},"ml-concepts/ch01-08-representation.html#cleaning-data":{"id":"ml-concepts/ch01-08-representation.html#cleaning-data","breadcrumbs":"ML Concepts » Cleaning Data","body":"scaling: floating-point feature value를 일정한 범위를 갖도록 변환하는 작업 feature가 하나일 때는 효과가 거의 없지만, 다수의 feature가 있을 때는 다음과 같은 효과가 있음 gradient descent에서 더 빠르게 converge함 NaN trap 회피: training에서 floating-point의 표현 범위를 벗어나는 경우 model이 각각의 feature에 대해 적절한 weight를 학습하도록 도움: scaling이 없으면 더 큰 범위를 가진 feature의 영향력이 지나치게 커질 수 있음 반드시 모든 feature가 같은 범위로 scale될 필요는 없음 Z score \\( scalevalue = (value - mean) / stddev \\) outlier 처리 log scaling clipping binning feature와 label의 관계가 비선형일 때, feature를 여러 개의 bin에 나눠 담아서 구간별로 다른 weight를 갖도록 함 scrubbing: 누락되거나 틀린 data를 처리 누락 중복 오답 잘못 측정된 feature value","title":"Cleaning Data"},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"title":"Training and Test Sets","breadcrumbs":"ML Concepts » Training and Test Sets","id":"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets","body":""},"ml-concepts/ch01-05-generalization.html#generalization":{"title":"Generalization","body":"","breadcrumbs":"ML Concepts » Generalization","id":"ml-concepts/ch01-05-generalization.html#generalization"},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"breadcrumbs":"ML Concepts » Stochastic Gradient Descent","id":"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent","body":"batch: 1번의 iteration에 사용되는 examples 집합 batch size: batch안의 examples 수 full-batch: batch size = number of examples data가 크면 계산이 오래 걸림 stochastic gradient descent: batch size = 1 noise가 심함 mini-batch stochastic gradient descent: batch size = 10 ~ 1000 noise는 줄이고, 계산 효율은 올리고","title":"Stochastic Gradient Descent"},"appendix/appendix.html#appendix":{"title":"Appendix","id":"appendix/appendix.html#appendix","body":"","breadcrumbs":"Appendix"},"appendix/a-cheat-sheet.html#linear-regression":{"id":"appendix/a-cheat-sheet.html#linear-regression","body":"선형 데이터를 표현하고 예측함 \\[ \\vec{y} = W\\vec{x} + b \\] \\[ \\vec{y}: label \\quad W: weight \\quad x: feature \\quad b: bias \\]","breadcrumbs":"Appendix » Linear regression","title":"Linear regression"},"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"id":"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity","title":"Encoding Nonlinearity","body":"feature cross: 두 개 이상의 feature의 곱으로 만든 synthetic feature, 비 선형적 관계를 표현할 수 있음","breadcrumbs":"ML Concepts » Encoding Nonlinearity"},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"id":"ml-concepts/ch01-08-representation.html#qualities-of-good-features","body":"드물게 사용되는 value는 feature로 사용하지 말 것 단 한번, 혹은 아주 드물게 사용되는 value는 model이 제대로 학습에 활용할 수 없음 Feature는 명확한 의미를 가져야 함 보는 이에 따라 다르게 해석될 여지가 있으면 안됨 noise에도 주의 Magic value 사용 금지 어떤 값의 상태를 표현하기 위한 magic value는 model 학습을 방해함 ex) 0~1 범위의 feature에 값이 존재하지 않음을 표현하기 위해 magic value -1을 할당 (이런 경우 존재 여부를 표현하기 위한 boolean feature를 따로 만드는게 좋음) 상황에 따라 변하는 value는 사용하지 말 것 ex) 다른 model에서 예측한 값","breadcrumbs":"ML Concepts » Qualities of Good Features","title":"Qualities of Good Features"},"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"body":"overfitting을 막기 위해 loss만 최소화 하는 대신 complexity를 추가 한다 L2 regularization: complextity = weight들의 제곱의 합","title":"L2 Regularization","breadcrumbs":"ML Concepts » L2 Regularization","id":"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization"},"ml-concepts/ch01-07-validation.html#another-partition":{"body":"validation set: a subset to validate the model. training set으로 모델을 학습시키고, validation set을 사용해서 모델을 조정한다. 마지막으로 test set을 사용해서 모델을 검증한다. 모델 학습 과정에서 test set의 노출을 최소화 해야 함. (ML의 목표는 새로운 데이터를 예측하는 것임)","title":"Another Partition","breadcrumbs":"ML Concepts » Another Partition","id":"ml-concepts/ch01-07-validation.html#another-partition"},"appendix/a-cheat-sheet.html#a---cheat-sheet":{"body":"","title":"A - Cheat sheet","id":"appendix/a-cheat-sheet.html#a---cheat-sheet","breadcrumbs":"Appendix » A - Cheat sheet"},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"body":"training set: a subset to train a model. test set: a subset to test the model. Never train on test data.","title":"Splitting Data","id":"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data","breadcrumbs":"ML Concepts » Splitting Data"},"ml-concepts/ch01-08-representation.html#feature-engineering":{"breadcrumbs":"ML Concepts » Feature Engineering","title":"Feature Engineering","body":"Raw data로부터 유의미한 feature들을 만들어 내는 과정 Integer/floating-pont는 별도의 encoding과정이 필요 없음 String같이 model이 직접적으로 학습에 사용할 수 없는 (계산 불가) 데이터는 encoding 필요 vocabulary: feature에 등장할 수 있는 모든 string value들의 집합 one-hot encoding: binary vector에서 하나의 element만 1이고 나머지는 0으로 설정","id":"ml-concepts/ch01-08-representation.html#feature-engineering"},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"breadcrumbs":"ML Concepts » Peril of Overfitting","body":"overfitting: making a model more complex than necessary 훈련에 사용된 데이터는 잘 표현하지만, 새로운 데이터를 예측하지 못함 A machine learning model aims to make good predictions on new, previously unseen data. 훈련에 사용한 데이터로 테스트 하면 안됨 Key assumptions of supervised ML Draw examples independently and identically (i.i.d) at random from the distribution. The distribution doesn't change within the data set. Draw examples from partitions from the same distribution.","title":"Peril of Overfitting","id":"ml-concepts/ch01-05-generalization.html#peril-of-overfitting"},"ml-concepts/ch01-17-embeddings.html#embeddings":{"title":"Embeddings","breadcrumbs":"ML Concepts » Embeddings","id":"ml-concepts/ch01-17-embeddings.html#embeddings","body":""}},"docInfo":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"title":2,"breadcrumbs":4,"body":18},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"body":0,"breadcrumbs":4,"title":2},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"breadcrumbs":4,"title":2,"body":39},"ml-concepts/ch01-10-regularization-simplicity.html#lambda":{"breadcrumbs":3,"body":14,"title":1},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"title":3,"breadcrumbs":4,"body":13},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"title":3,"body":32,"breadcrumbs":5},"ml-concepts/ch01-07-validation.html#another-partition":{"breadcrumbs":4,"body":14,"title":2},"ml-concepts/ch01-01-framing.html#ml-terminology":{"body":29,"title":2,"breadcrumbs":4},"ml-concepts/ch01-07-validation.html#validation":{"title":1,"breadcrumbs":3,"body":0},"ml-concepts/ch01-12-classification.html#classification":{"body":0,"title":1,"breadcrumbs":3},"appendix/a-cheat-sheet.html#a---cheat-sheet":{"title":2,"body":0,"breadcrumbs":3},"ml-concepts/ch01-09-feature-crosses.html#encoding-nonlinearity":{"body":5,"breadcrumbs":4,"title":2},"appendix/a-cheat-sheet.html#supervised-learning":{"body":12,"breadcrumbs":3,"title":2},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"breadcrumbs":3,"body":62,"title":1},"appendix/appendix.html#appendix":{"breadcrumbs":1,"title":1,"body":0},"ml-concepts/ch01-08-representation.html#cleaning-data":{"title":2,"body":42,"breadcrumbs":4},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"title":2,"body":17,"breadcrumbs":4},"appendix/a-cheat-sheet.html#terminology":{"breadcrumbs":2,"title":1,"body":57},"ml-concepts/ch01-09-feature-crosses.html#crossing-one-hot-vectors":{"title":4,"body":0,"breadcrumbs":6},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"breadcrumbs":4,"body":0,"title":2},"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"breadcrumbs":5,"body":0,"title":3},"ml-concepts/ch01-01-framing.html#framing":{"breadcrumbs":3,"title":1,"body":0},"appendix/a-cheat-sheet.html#linear-regression":{"title":2,"body":14,"breadcrumbs":3},"ml-concepts/ch01-08-representation.html#qualities-of-good-features":{"body":22,"title":3,"breadcrumbs":5},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"body":8,"breadcrumbs":2,"title":2},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"breadcrumbs":4,"body":13,"title":2},"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"title":2,"body":0,"breadcrumbs":4},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"breadcrumbs":4,"body":0,"title":2},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"body":28,"title":2,"breadcrumbs":4},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"body":0,"title":4,"breadcrumbs":6},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"breadcrumbs":5,"title":3,"body":0},"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"title":2,"body":0,"breadcrumbs":4},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"breadcrumbs":5,"title":3,"body":0},"ml-concepts/ch01-10-regularization-simplicity.html#l2-regularization":{"breadcrumbs":4,"title":2,"body":7},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"body":4,"breadcrumbs":5,"title":3},"ml-concepts/ch01-05-generalization.html#generalization":{"title":1,"breadcrumbs":3,"body":0},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"breadcrumbs":2,"title":2,"body":5},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"title":2,"body":21,"breadcrumbs":4},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"body":0,"title":2,"breadcrumbs":4},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"breadcrumbs":5,"body":0,"title":3},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"title":2,"body":14,"breadcrumbs":4},"ml-concepts/ch01-08-representation.html#feature-engineering":{"body":21,"breadcrumbs":4,"title":2},"ml-concepts/ch01-17-embeddings.html#embeddings":{"title":1,"body":0,"breadcrumbs":3},"ml-concepts/ch01-08-representation.html#representation":{"breadcrumbs":3,"title":1,"body":0}},"length":44}}};