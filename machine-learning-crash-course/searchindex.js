window.search = {"searchoptions":{"bool":"OR","expand":true,"limit_results":30,"teaser_word_count":30,"fields":{"title":{"boost":2},"body":{"boost":1},"breadcrumbs":{"boost":1}}},"index":{"fields":["title","body","breadcrumbs"],"pipeline":["trimmer","stopWordFilter","stemmer"],"ref":"id","version":"0.9.5","index":{"title":{"root":{"df":0,"docs":{},"e":{"df":0,"docs":{},"m":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-17-embeddings.html#embeddings":{"tf":1.0}}}}}}},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"u":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":3,"docs":{"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0}}}}}},"t":{"df":3,"docs":{"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0}}}}},"m":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0}}}}}},"l":{"df":4,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}},"t":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0}}}},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"w":{"df":1,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}}}}}},"r":{"df":0,"docs":{},"m":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"g":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}}}}}}}},"f":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":3,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"k":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"p":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"f":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-01-framing.html#framing":{"tf":1.0}}}}}},"i":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"u":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0}}}}}}}},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}},"n":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0}}}}}}}}}}},"c":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"n":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}}}}}},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.0}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0}},"i":{"df":0,"docs":{},"f":{"df":1,"docs":{"ml-concepts/ch01-12-classification.html#classification":{"tf":1.0}}}}}}}}},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0}}}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#generalization":{"tf":1.0}}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"g":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":2,"docs":{"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":3,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0}}}}},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#representation":{"tf":1.0}}}}}}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"e":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0}}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}}},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0}}}},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.0}}}}}},"i":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0}}}}}}}},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"i":{"df":0,"docs":{},"f":{"df":1,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0}}}}}}}}},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}}}},"e":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0}}}}},"u":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"v":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":1,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}}}}}},"v":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-07-validation.html#validation":{"tf":1.0}}}}}}},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.0}}},"t":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0}}}}}},"a":{"df":0,"docs":{},"p":{"df":0,"docs":{},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"a":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"x":{"df":1,"docs":{"appendix/appendix.html#appendix":{"tf":1.0}}}}}}}}},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0}}}}}}},"l":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"n":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0}}}}}},"s":{"df":0,"docs":{},"s":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0}}}}},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}}}}}}}}},"body":{"root":{"df":0,"docs":{},"u":{"df":0,"docs":{},"n":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952}}}}}}},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"k":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.4142135623730952}},"(":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"w":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.7320508075688773},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.6457513110645909},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952}}}}}}}}}},"r":{"df":0,"docs":{},"m":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"g":{"df":3,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}}}}}},"s":{"df":0,"docs":{},"t":{"df":3,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.7320508075688773},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.4142135623730952},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0}}}}},"f":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0}},".":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"y":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":8,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.7320508075688773},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}}}},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}}}}}},"u":{"df":0,"docs":{},"t":{"df":0,"docs":{},"p":{"df":0,"docs":{},"u":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952}}}}}}},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952}}}},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0}}}}}}},"q":{"df":0,"docs":{},"u":{"df":0,"docs":{},"a":{"df":0,"docs":{},"d":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.7320508075688773}}}}}},"k":{"df":0,"docs":{},"e":{"df":0,"docs":{},"y":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"h":{"df":0,"docs":{},"t":{"df":0,"docs":{},"t":{"df":0,"docs":{},"p":{"df":0,"docs":{},"s":{"df":0,"docs":{},":":{"df":0,"docs":{},"/":{"df":0,"docs":{},"/":{"df":0,"docs":{},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"u":{"df":0,"docs":{},"b":{"df":0,"docs":{},".":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":0,"docs":{},"/":{"df":0,"docs":{},"j":{"df":0,"docs":{},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":0,"docs":{},"/":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"df":0,"docs":{},"/":{"df":0,"docs":{},"/":{"df":0,"docs":{},"j":{"df":0,"docs":{},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":0,"docs":{},".":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":0,"docs":{},"/":{"df":0,"docs":{},"2":{"df":0,"docs":{},"0":{"df":0,"docs":{},"1":{"df":0,"docs":{},"6":{"df":0,"docs":{},"/":{"df":0,"docs":{},"0":{"df":0,"docs":{},"5":{"df":0,"docs":{},"/":{"df":0,"docs":{},"2":{"df":0,"docs":{},"3":{"df":0,"docs":{},"/":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"y":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"p":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}}}}}}}},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.4142135623730952}}}}}},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":6,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}}},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":2,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0}}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}}}}}}},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#representation":{"tf":1.0}}}}}}}}},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0}}}}}},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"k":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"t":{"df":0,"docs":{},"e":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":2.23606797749979}}}}}},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":0,"docs":{},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"g":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"u":{"df":2,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}}},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0}}}}}}},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"e":{"df":0,"docs":{},"x":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"m":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"n":{"df":0,"docs":{},"g":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0}}}}}},"p":{"df":0,"docs":{},"u":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":3,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}},"i":{"df":0,"docs":{},"f":{"df":3,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-12-classification.html#classification":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}}}}}},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"b":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}}}}}},"o":{"df":0,"docs":{},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0}}}}}},"s":{"df":0,"docs":{},"s":{"df":5,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":2.6457513110645909},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":2.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0}}}},"w":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"a":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":5,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.7320508075688773},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"l":{"df":1,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"n":{"df":5,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":2.449489742783178}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.0}}}}}},"_":{"df":0,"docs":{},"2":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"1":{"df":4,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}},"0":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}},"0":{"df":0,"docs":{},"0":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"f":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":4,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":0,"docs":{},"c":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}}}},"t":{"df":0,"docs":{},"e":{"df":0,"docs":{},"g":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}},"r":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}}},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0}}}}}}}}}},".":{"df":0,"docs":{},"i":{"df":0,"docs":{},".":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"c":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"b":{"df":0,"docs":{},"u":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.7320508075688773},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":6,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"w":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}}},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"n":{"df":0,"docs":{},"'":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"v":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0}}}}},"s":{"df":0,"docs":{},"c":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.0}}},"t":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0}}}}}}}}},"n":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"u":{"df":0,"docs":{},"m":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}}},"u":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":3,"docs":{"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0}}}}}},"t":{"df":3,"docs":{"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0}}}}},"w":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}},"o":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.4142135623730952}}}},"d":{"df":0,"docs":{},"e":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"m":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}},"m":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"s":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":9,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.7320508075688773},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"l":{"df":6,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}},"a":{"df":0,"docs":{},"k":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}}},"w":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}},"x":{"df":0,"docs":{},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"h":{"df":0,"docs":{},"t":{"df":6,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}}}}}},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"\\":{"df":0,"docs":{},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"{":{"df":0,"docs":{},"x":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}}}}}}}},"x":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}},"y":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.7320508075688773}}},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":4,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":2.23606797749979},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0}}},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"u":{"df":0,"docs":{},"b":{"df":0,"docs":{},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952}}}}}},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"v":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":2,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}}},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0}}}}}}}},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"i":{"df":0,"docs":{},"f":{"df":1,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}}},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.0}}}}}},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"z":{"df":0,"docs":{},"e":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0}}}}}}}},"c":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}},"t":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":3,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"g":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.7320508075688773}}}}}}}}},"q":{"df":0,"docs":{},"u":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952}}}}}}},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"i":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0}}}}}},"u":{"df":0,"docs":{},"n":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}}}},"l":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"u":{"df":0,"docs":{},"r":{"df":5,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952}}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-01-framing.html#framing":{"tf":1.0}}}}}}},"j":{"df":0,"docs":{},"v":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"p":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.7320508075688773}}},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"x":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}},"a":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"x":{"df":1,"docs":{"appendix/appendix.html#appendix":{"tf":1.0}}}}}}}}},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0}}}}}},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"m":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}}}}}}}},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}}},"g":{"df":0,"docs":{},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#generalization":{"tf":1.0}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":4,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":2.0}}}}}}},"p":{"df":0,"docs":{},"h":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.23606797749979}}}}}},"p":{"df":0,"docs":{},"u":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"p":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.7320508075688773},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}},"a":{"df":0,"docs":{},"l":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":6,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952}}}}}},"v":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"o":{"df":0,"docs":{},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"f":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"n":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}}}},"o":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"i":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-17-embeddings.html#embeddings":{"tf":1.0}}}}}},"r":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"n":{"df":0,"docs":{},"c":{"df":0,"docs":{},"a":{"df":0,"docs":{},"p":{"df":0,"docs":{},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"x":{"df":5,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":6,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.7320508075688773},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}}},"d":{"df":0,"docs":{},"g":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}},"v":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"u":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952}}},"i":{"df":0,"docs":{},"d":{"df":2,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.7320508075688773},"ml-concepts/ch01-07-validation.html#validation":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}},"{":{"df":0,"docs":{},"i":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952}}}}}}},"b":{"df":2,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952}},"a":{"df":0,"docs":{},"d":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}},"t":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.8284271247461905},"appendix/a-cheat-sheet.html#terminology":{"tf":1.7320508075688773}}}}}},"i":{"df":0,"docs":{},"a":{"df":2,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}},"u":{"df":0,"docs":{},"f":{"df":0,"docs":{},"f":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952}}}}}}}},"breadcrumbs":{"root":{"df":0,"docs":{},"k":{"df":0,"docs":{},"e":{"df":0,"docs":{},"y":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"f":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"u":{"df":0,"docs":{},"r":{"df":5,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952}}}}}}},"u":{"df":0,"docs":{},"n":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0}}}}}}}},"l":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"i":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.4142135623730952}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-01-framing.html#framing":{"tf":1.4142135623730952}}}}}}},"s":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"h":{"df":0,"docs":{},"e":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.4142135623730952}}}}}},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"g":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.0}}}}}}}},"e":{"df":0,"docs":{},"p":{"df":3,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}}},"c":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}}}}},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"i":{"df":0,"docs":{},"f":{"df":1,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952}}}}}},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.4142135623730952}}}}}}}},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952}}}}}},"q":{"df":0,"docs":{},"u":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952}}}}}},"u":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"v":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":2,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"b":{"df":0,"docs":{},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0}}}}}}},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"z":{"df":0,"docs":{},"e":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952}}}},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.4142135623730952}}}}}}}},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"t":{"df":4,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":2.23606797749979},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.4142135623730952}}}}},"j":{"df":0,"docs":{},"v":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"1":{"df":4,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}},"0":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}},"0":{"df":0,"docs":{},"0":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"b":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":3,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0}}}}}}},"_":{"df":0,"docs":{},"2":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"a":{"df":0,"docs":{},"b":{"df":0,"docs":{},"l":{"df":1,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}},"e":{"df":0,"docs":{},"l":{"df":5,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0}}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"n":{"df":5,"docs":{"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.7320508075688773},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":2.6457513110645909},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.0}}}}}},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":5,"docs":{"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":2.8284271247461905},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":2.0}}}},"w":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.4142135623730952}}}}}}}},"v":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"i":{"df":0,"docs":{},"d":{"df":2,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.7320508075688773},"ml-concepts/ch01-07-validation.html#validation":{"tf":1.4142135623730952}}}},"u":{"df":2,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952}}}}},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"{":{"df":0,"docs":{},"i":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952}}}},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}},"n":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"e":{"df":0,"docs":{},"t":{"df":3,"docs":{"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.4142135623730952}}},"w":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0}}}}},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}}},"u":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":3,"docs":{"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.4142135623730952}}}}}}},"u":{"df":0,"docs":{},"m":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}}}}}}},"o":{"df":0,"docs":{},"i":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.4142135623730952}}}},"d":{"df":0,"docs":{},"e":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"u":{"df":0,"docs":{},"t":{"df":0,"docs":{},"p":{"df":0,"docs":{},"u":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.4142135623730952}}}}}}},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.4142135623730952}}}},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.4142135623730952}}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.7320508075688773}}}}}}}}},"w":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}},"\\":{"df":0,"docs":{},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"{":{"df":0,"docs":{},"x":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}}}}}}},"e":{"df":0,"docs":{},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"h":{"df":0,"docs":{},"t":{"df":6,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}},"x":{"df":0,"docs":{},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}}},"x":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}},"_":{"df":0,"docs":{},"1":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}},"d":{"df":0,"docs":{},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"n":{"df":0,"docs":{},"'":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":6,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"w":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}}},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"b":{"df":0,"docs":{},"u":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.7320508075688773}}}}}}}},"c":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"c":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.4142135623730952}}},"t":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.0}}}}}}},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"v":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0}}}}}}},"m":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":9,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.4142135623730952},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}},"r":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"s":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"c":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"k":{"df":0,"docs":{},"e":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.4142135623730952}}}}}},"l":{"df":31,"docs":{"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-17-embeddings.html#embeddings":{"tf":1.0},"ml-concepts/ch01-12-classification.html#classification":{"tf":1.0},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0},"ml-concepts/ch01-08-representation.html#representation":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#generalization":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.4142135623730952},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-07-validation.html#validation":{"tf":1.0},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.7320508075688773},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#framing":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.7320508075688773}}},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0}},"m":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"i":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-17-embeddings.html#embeddings":{"tf":1.4142135623730952}}}}}},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"d":{"df":0,"docs":{},"g":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"x":{"df":5,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":6,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.7320508075688773},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}}},"r":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952}}}}}},"n":{"df":0,"docs":{},"c":{"df":0,"docs":{},"a":{"df":0,"docs":{},"p":{"df":0,"docs":{},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}}},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":4,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":2.23606797749979}}}}}}},"p":{"df":0,"docs":{},"h":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.23606797749979},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952}}}}}},"p":{"df":0,"docs":{},"u":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#generalization":{"tf":1.4142135623730952}}}}}}},"b":{"df":2,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952}},"i":{"df":0,"docs":{},"a":{"df":2,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0}}}},"u":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952}}}},"f":{"df":0,"docs":{},"f":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":2.8284271247461905},"appendix/a-cheat-sheet.html#terminology":{"tf":1.7320508075688773}}}}},"d":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"m":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0}}}}}}}}}},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}},"p":{"df":0,"docs":{},"i":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.7320508075688773}}},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"x":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}},"a":{"df":0,"docs":{},"c":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.4142135623730952}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"x":{"df":6,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.0},"appendix/appendix.html#appendix":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}}}}},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.4142135623730952}}}}}}},"p":{"df":0,"docs":{},"o":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"f":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"v":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"d":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":6,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":2.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952}}}}}}},"o":{"df":0,"docs":{},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"a":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}}}},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"l":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.4142135623730952}}}}}},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.4142135623730952},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}},"a":{"df":0,"docs":{},"l":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.7320508075688773}}}}}}},"s":{"df":0,"docs":{},"s":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}},"c":{"df":0,"docs":{},"p":{"df":0,"docs":{},"u":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.4142135623730952}}}}}},"h":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":0,"docs":{},"g":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":1,"docs":{"appendix/a-cheat-sheet.html#a---cheat-sheet":{"tf":1.4142135623730952}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":3,"docs":{"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}},"i":{"df":0,"docs":{},"f":{"df":3,"docs":{"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-12-classification.html#classification":{"tf":1.4142135623730952}}}}}}}},"o":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"u":{"df":2,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0}}}}}},"v":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"g":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":30,"docs":{"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.0},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.0},"ml-concepts/ch01-08-representation.html#representation":{"tf":1.0},"ml-concepts/ch01-17-embeddings.html#embeddings":{"tf":1.0},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"tf":1.0},"ml-concepts/ch01-07-validation.html#validation":{"tf":1.0},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.0},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"tf":1.0},"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0},"ml-concepts/ch01-12-classification.html#classification":{"tf":1.0},"ml-concepts/ch01-05-generalization.html#generalization":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.0},"ml-concepts/ch01-01-framing.html#framing":{"tf":1.0}}}}}}},"m":{"df":0,"docs":{},"p":{"df":0,"docs":{},"l":{"df":0,"docs":{},"e":{"df":0,"docs":{},"x":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"m":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}},"t":{"df":0,"docs":{},"o":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"k":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.7320508075688773}},"(":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":8,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.7320508075688773},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.7320508075688773},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.4142135623730952},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.0},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.7320508075688773},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0}}}}}},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"m":{"df":0,"docs":{},"i":{"df":0,"docs":{},"n":{"df":0,"docs":{},"o":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"g":{"df":3,"docs":{"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.4142135623730952}}}}}}}}}},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"o":{"df":0,"docs":{},"r":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}},"f":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"w":{"df":3,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":2.6457513110645909},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":2.0}}}}}}}}}},"s":{"df":0,"docs":{},"t":{"df":3,"docs":{"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"tf":1.7320508075688773},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"tf":1.4142135623730952},"ml-concepts/ch01-07-validation.html#another-partition":{"tf":1.4142135623730952}}}}},"f":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"tf":1.4142135623730952}},".":{"df":0,"docs":{},"l":{"df":0,"docs":{},"o":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"y":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"i":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}}}}}},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"h":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.4142135623730952}}}}},"t":{"df":0,"docs":{},"t":{"df":0,"docs":{},"p":{"df":0,"docs":{},"s":{"df":0,"docs":{},":":{"df":0,"docs":{},"/":{"df":0,"docs":{},"/":{"df":0,"docs":{},"g":{"df":0,"docs":{},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"h":{"df":0,"docs":{},"u":{"df":0,"docs":{},"b":{"df":0,"docs":{},".":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":0,"docs":{},"/":{"df":0,"docs":{},"j":{"df":0,"docs":{},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":0,"docs":{},"/":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},":":{"df":0,"docs":{},"/":{"df":0,"docs":{},"/":{"df":0,"docs":{},"j":{"df":0,"docs":{},"o":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":0,"docs":{},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"s":{"df":0,"docs":{},".":{"df":0,"docs":{},"c":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":0,"docs":{},"/":{"df":0,"docs":{},"2":{"df":0,"docs":{},"0":{"df":0,"docs":{},"1":{"df":0,"docs":{},"6":{"df":0,"docs":{},"/":{"df":0,"docs":{},"0":{"df":0,"docs":{},"5":{"df":0,"docs":{},"/":{"df":0,"docs":{},"2":{"df":0,"docs":{},"3":{"df":0,"docs":{},"/":{"df":0,"docs":{},"f":{"df":0,"docs":{},"i":{"df":0,"docs":{},"z":{"df":0,"docs":{},"z":{"df":1,"docs":{"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.0}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}},"y":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"p":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":0,"docs":{},"a":{"df":0,"docs":{},"m":{"df":0,"docs":{},"e":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0}}}}}}}}}}}}}},"i":{"df":0,"docs":{},"t":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":3,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.4142135623730952}}}}},"n":{"df":0,"docs":{},"t":{"df":0,"docs":{},"r":{"df":0,"docs":{},"o":{"df":0,"docs":{},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"tf":1.4142135623730952},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"tf":1.4142135623730952}}}}}}}},"e":{"df":0,"docs":{},"r":{"df":0,"docs":{},"c":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}},"g":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"p":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"f":{"df":0,"docs":{},"e":{"df":0,"docs":{},"r":{"df":4,"docs":{"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}},"s":{"df":0,"docs":{},"t":{"df":0,"docs":{},"a":{"df":0,"docs":{},"n":{"df":0,"docs":{},"c":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0}}}}}}}},"d":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},".":{"df":0,"docs":{},"i":{"df":0,"docs":{},".":{"df":0,"docs":{},"d":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}},"u":{"df":0,"docs":{},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"i":{"df":0,"docs":{},"g":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"e":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"b":{"df":0,"docs":{},"e":{"df":0,"docs":{},"l":{"df":2,"docs":{"appendix/a-cheat-sheet.html#terminology":{"tf":1.4142135623730952},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.4142135623730952}}}}}}}}},"q":{"df":0,"docs":{},"u":{"df":0,"docs":{},"a":{"df":0,"docs":{},"d":{"df":1,"docs":{"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.7320508075688773}}}}}},"r":{"df":0,"docs":{},"u":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0}}}}}}},"e":{"df":0,"docs":{},"g":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"s":{"df":6,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.4142135623730952},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"tf":1.0},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"tf":1.4142135623730952},"appendix/a-cheat-sheet.html#supervised-learning":{"tf":1.0},"ml-concepts/ch01-01-framing.html#ml-terminology":{"tf":1.0},"appendix/a-cheat-sheet.html#linear-regression":{"tf":1.4142135623730952}}}}}},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"r":{"df":2,"docs":{"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"tf":1.4142135623730952},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"tf":1.4142135623730952}}}}}}},"s":{"df":0,"docs":{},"u":{"df":0,"docs":{},"l":{"df":0,"docs":{},"t":{"df":2,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"tf":1.0},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"tf":1.0}}}}}},"p":{"df":0,"docs":{},"r":{"df":0,"docs":{},"e":{"df":0,"docs":{},"s":{"df":0,"docs":{},"e":{"df":0,"docs":{},"n":{"df":0,"docs":{},"t":{"df":1,"docs":{"ml-concepts/ch01-08-representation.html#representation":{"tf":1.4142135623730952}}}}}}}}},"l":{"df":0,"docs":{},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"i":{"df":0,"docs":{},"o":{"df":0,"docs":{},"n":{"df":0,"docs":{},"s":{"df":0,"docs":{},"h":{"df":0,"docs":{},"i":{"df":0,"docs":{},"p":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.0}}}}}}}}}}}},"d":{"df":0,"docs":{},"u":{"df":0,"docs":{},"c":{"df":1,"docs":{"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"tf":1.4142135623730952}}}}}},"i":{"df":0,"docs":{},"s":{"df":0,"docs":{},"k":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"tf":1.0}}}}},"a":{"df":0,"docs":{},"t":{"df":0,"docs":{},"e":{"df":3,"docs":{"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"tf":2.449489742783178},"appendix/a-cheat-sheet.html#terminology":{"tf":1.0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"tf":1.7320508075688773}}}},"n":{"df":0,"docs":{},"d":{"df":0,"docs":{},"o":{"df":0,"docs":{},"m":{"df":1,"docs":{"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"tf":1.0}}}}}}}},"y":{"df":1,"docs":{"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"tf":1.7320508075688773}}}}}},"documentStore":{"save":true,"docs":{"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"id":"ml-concepts/ch01-04-first-steps-with-th.html#toolkit","breadcrumbs":"ML Concepts » Toolkit","body":"tensorflow toolkit 계층 구조 Toolkit(s) Description Estimator High-level, OOP API tf.layers / tf.losses / tf.metrics Libraries for common model components Tensorflow Lower-level APIs 처음엔 high-level API를 사용하고, 모델을 더 유연하게 확장하고 싶을 때 low-level을 사용 Tensorflow는 graph protocol buffer와 (distributed) graph를 실행하기 위한 runtime으로 구성됨 JVM이 다양한 platform에서 동작하듯이 tensorflow로 CPU와 GPU에서 동작함 tf.estimator: tensorflow graph 생성과 session 실행을 encapsulate한 모듈 graph: tensorflow에서 계산 과정은 graph로 표현됨 nodes: operations edges: passing the result of an operation (directed) tensor: tensorflow의 기본 자료 구조 (N차원 자료 구조) scalars, vectors, matrices integer, floating-point, string","title":"Toolkit"},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"breadcrumbs":"Appendix » Terminology: Tensorflow specific","id":"appendix/a-cheat-sheet.html#terminology-tensorflow-specific","title":"Terminology: Tensorflow specific","body":"graph: tensorflow에서 계산 과정은 graph로 표현됨 nodes: operations edges: passing the result of an operation (directed) tensor: tensorflow의 기본 자료 구조 (N차원 자료 구조)"},"appendix/a-cheat-sheet.html#supervised-learning":{"breadcrumbs":"Appendix » Supervised learning","body":"labled example로 model을 학습시킴 Regression Continuous value를 예측 Output이 연속적인 값 Classification Discrete value를 예측 Output이 class","title":"Supervised learning","id":"appendix/a-cheat-sheet.html#supervised-learning"},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"id":"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml","body":"기계 학습을 배우면 개발 시간을 줄일 수 있다. (항상 그렇진 않음) 잘못 된 예 http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/ https://github.com/joelgrus/fizz-buzz-tensorflow/ 하나의 모델로 데이터만 바꿔서 다른 프로그램을 만들 수 있다. ex) 기계 번역 규칙 기반으로 해결할 수 없는 문제를 해결할 수 있다. ex) 고양이 사진 분류","title":"Introduction to ML","breadcrumbs":"Introduction to ML"},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"id":"ml-concepts/ch01-02-descending-into-ml.html#linear-regression","title":"Linear Regression","body":"linear relationship: \\( y' = b + w_1x_1 \\) \\( y' \\): predicted label \\( b \\): bias (y-intercept) \\( w_1 \\): weight of feature 1 \\( x_1 \\): feature inference \\( \\approx \\) predict","breadcrumbs":"ML Concepts » Linear Regression"},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"breadcrumbs":"ML Concepts » Introduction to Neural Nets","title":"Introduction to Neural Nets","body":"","id":"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets"},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"id":"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss","title":"Training and Loss","breadcrumbs":"ML Concepts » Training and Loss","body":"training: empirical risk minimization examples를 통해 loss를 최소화 하는 model을 찾는 과정 error: label과 prediction의 차이 signed loss: bad prediction에 대한 penalty unsigned loss function: loss를 계산하기 위한 함수 ex) squared loss(\\( L_2 \\) loss), mean square error (MSE)"},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"id":"ml-concepts/ch01-03-reducing-loss.html#gradient-descent","title":"Gradient Descent","body":"linear regression에서 weight 와 loss의 관계를 좌표평면에 그려보면 밥그릇 모양이 그려지는데, 경사를 따라 내려가면서 loss를 최소화하는 weight를 찾는 방법 gradient: vector of partial derivatives vector이르모 방향과 정량적인 값을 가짐 gradient는 항상 loss function의 가장 가파른 곳을 향한다 loss를 줄이기 위해 gradient의 반대 방향으로 weight를 갱신해야 함","breadcrumbs":"ML Concepts » Gradient Descent"},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"body":"","id":"ml-concepts/ch01-09-feature-crosses.html#feature-crosses","title":"Feature Crosses","breadcrumbs":"ML Concepts » Feature Crosses"},"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"body":"","id":"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets","breadcrumbs":"ML Concepts » Training Neural Nets","title":"Training Neural Nets"},"ml-concepts/ch01-17-embeddings.html#embeddings":{"title":"Embeddings","id":"ml-concepts/ch01-17-embeddings.html#embeddings","breadcrumbs":"ML Concepts » Embeddings","body":""},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"title":"ML Concepts","breadcrumbs":"ML Concepts","id":"ml-concepts/ch00-00-ml-concepts.html#ml-concepts","body":""},"ml-concepts/ch01-08-representation.html#representation":{"title":"Representation","id":"ml-concepts/ch01-08-representation.html#representation","body":"","breadcrumbs":"ML Concepts » Representation"},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"body":"overfitting: making a model more complex than necessary 훈련에 사용된 데이터는 잘 표현하지만, 새로운 데이터를 예측하지 못함 A machine learning model aims to make good predictions on new, previously unseen data. 훈련에 사용한 데이터로 테스트 하면 안됨 Key assumptions of supervised ML Draw examples independently and identically (i.i.d) at random from the distribution. The distribution doesn't change within the data set. Draw examples from partitions from the same distribution.","breadcrumbs":"ML Concepts » Peril of Overfitting","id":"ml-concepts/ch01-05-generalization.html#peril-of-overfitting","title":"Peril of Overfitting"},"ml-concepts/ch01-07-validation.html#validation":{"title":"Validation","body":"","breadcrumbs":"ML Concepts » Validation","id":"ml-concepts/ch01-07-validation.html#validation"},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"id":"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach","title":"An Iterative Approach","body":"parameter: model의 변수 ex) weight convergence: training이 진행되면서 loss가 고정되거나 극단적으로 느리게 변하는 상태 모델은 다음과 같은 반복적인 계산을 통해 학습된다 parameter 초기화 prediction 생성 (inference) loss 계산 parameter 갱신 1번으로","breadcrumbs":"ML Concepts » An Iterative Approach"},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"body":"training set: a subset to train a model. test set: a subset to test the model. Never train on test data.","breadcrumbs":"ML Concepts » Splitting Data","title":"Splitting Data","id":"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data"},"ml-concepts/ch01-05-generalization.html#generalization":{"body":"","title":"Generalization","id":"ml-concepts/ch01-05-generalization.html#generalization","breadcrumbs":"ML Concepts » Generalization"},"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"body":"","id":"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity","breadcrumbs":"ML Concepts » Regularization: Simplicity","title":"Regularization: Simplicity"},"appendix/a-cheat-sheet.html#terminology":{"id":"appendix/a-cheat-sheet.html#terminology","title":"Terminology","body":"label: 예측할 대상 feature: 입력 변수 prediction: 예측값 example: instance of data (labeled, unlabeled) model: feature와 label 사이의 관계를 정의함 training: model을 만들거나 학습시키는 과정 inference: trained model에 unlabeled example을 입력으로 주어 prediction을 얻는 과정 error: label과 prediction의 차이 loss: bad prediction에 대한 penalty loss function: loss를 계산하기 위한 함수 parameter: model의 변수 convergence: training이 진행되면서 loss가 고정되거나 극단적으로 느리게 변하는 상태 gradient: vector of partial derivatives learning rate (step size): weight를 갱신할 때 gradient에 곱해주는 scalar값 hyperparameter: machine learning algorithm을 최적화 하기 위해 프로그래머가 조작하는 값 batch: 1번의 iteration에 사용되는 examples 집합 batch size: batch안의 examples 수","breadcrumbs":"Appendix » Terminology"},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"title":"Stochastic Gradient Descent","body":"batch: 1번의 iteration에 사용되는 examples 집합 batch size: batch안의 examples 수 full-batch: batch size = number of examples data가 크면 계산이 오래 걸림 stochastic gradient descent: batch size = 1 noise가 심함 mini-batch stochastic gradient descent: batch size = 10 ~ 1000 noise는 줄이고, 계산 효율은 올리고","id":"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent","breadcrumbs":"ML Concepts » Stochastic Gradient Descent"},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"id":"ml-concepts/ch01-03-reducing-loss.html#reducing-loss","body":"","breadcrumbs":"ML Concepts » Reducing Loss","title":"Reducing Loss"},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"title":"Multi-class Neural Nets","breadcrumbs":"ML Concepts » Multi-class Neural Nets","body":"","id":"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets"},"appendix/appendix.html#appendix":{"body":"","id":"appendix/appendix.html#appendix","title":"Appendix","breadcrumbs":"Appendix"},"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"body":"","title":"First Steps with TF","id":"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf","breadcrumbs":"ML Concepts » First Steps with TF"},"appendix/a-cheat-sheet.html#a---cheat-sheet":{"body":"","breadcrumbs":"Appendix » A - Cheat sheet","id":"appendix/a-cheat-sheet.html#a---cheat-sheet","title":"A - Cheat sheet"},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"id":"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate","breadcrumbs":"ML Concepts » Optimizing Learning Rate","title":"Optimizing Learning Rate","body":"최적의 learning rate는 data와 algorithm의 특성에 따라 다름"},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"body":"","id":"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets","title":"Training and Test Sets","breadcrumbs":"ML Concepts » Training and Test Sets"},"ml-concepts/ch01-01-framing.html#ml-terminology":{"breadcrumbs":"ML Concepts » ML Terminology","body":"label: 예측할 대상. feature: 입력 변수. example: instance of data (labeled, unlabeled) model: feature와 label 사이의 관계를 정의함 training: model을 만들거나 학습시키는 과정 inference: trained model에 unlabeled example을 입력으로 주어 prediction을 얻는 과정 regression continuous value를 예측 output이 연속적인 값 ex) 판교의 집값은 얼마인가? classification discrete value를 예측 output이 class ex) 이 동물은 고양이인가?","id":"ml-concepts/ch01-01-framing.html#ml-terminology","title":"ML Terminology"},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"body":"","breadcrumbs":"ML Concepts » Regularization: Sparsity","id":"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity","title":"Regularization: Sparsity"},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"title":"Learning Rate","breadcrumbs":"ML Concepts » Learning Rate","body":"learning rate (step size): weight를 갱신할 때 gradient에 곱해주는 scalar값 learning rate가 너무 작으면 모델이 수렴하기까지 걸리는 시간이 길어짐 learning rate가 너무 크면 모델이 수렴하지 않거나 발산할 수 있음 hyperparameter: machine learning algorithm을 최적화 하기 위해 프로그래머가 조작하는 값 ex) learning rate","id":"ml-concepts/ch01-03-reducing-loss.html#learning-rate"},"appendix/a-cheat-sheet.html#linear-regression":{"body":"선형 데이터를 표현하고 예측함 \\[ \\vec{y} = W\\vec{x} + b \\] \\[ \\vec{y}: label \\quad W: weight \\quad x: feature \\quad b: bias \\]","breadcrumbs":"Appendix » Linear regression","id":"appendix/a-cheat-sheet.html#linear-regression","title":"Linear regression"},"ml-concepts/ch01-01-framing.html#framing":{"breadcrumbs":"ML Concepts » Framing","title":"Framing","body":"","id":"ml-concepts/ch01-01-framing.html#framing"},"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"breadcrumbs":"ML Concepts » Descending into ML","id":"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml","title":"Descending into ML","body":""},"ml-concepts/ch01-07-validation.html#another-partition":{"title":"Another Partition","breadcrumbs":"ML Concepts » Another Partition","id":"ml-concepts/ch01-07-validation.html#another-partition","body":"validation set: a subset to validate the model. training set으로 모델을 학습시키고, validation set을 사용해서 모델을 조정한다. 마지막으로 test set을 사용해서 모델을 검증한다. 모델 학습 과정에서 test set의 노출을 최소화 해야 함. (ML의 목표는 새로운 데이터를 예측하는 것임)"},"ml-concepts/ch01-12-classification.html#classification":{"body":"","title":"Classification","breadcrumbs":"ML Concepts » Classification","id":"ml-concepts/ch01-12-classification.html#classification"},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"id":"ml-concepts/ch01-11-logistic-regression.html#logistic-regression","breadcrumbs":"ML Concepts » Logistic Regression","title":"Logistic Regression","body":""}},"docInfo":{"ml-concepts/ch01-15-training-neural-nets.html#training-neural-nets":{"title":3,"body":0,"breadcrumbs":5},"appendix/a-cheat-sheet.html#linear-regression":{"title":2,"body":14,"breadcrumbs":3},"ml-concepts/ch01-09-feature-crosses.html#feature-crosses":{"title":2,"breadcrumbs":4,"body":0},"ml-concepts/ch01-17-embeddings.html#embeddings":{"title":1,"body":0,"breadcrumbs":3},"ml-concepts/ch01-05-generalization.html#generalization":{"body":0,"breadcrumbs":3,"title":1},"ml-concepts/ch01-04-first-steps-with-th.html#toolkit":{"breadcrumbs":3,"body":62,"title":1},"ml-concepts/ch01-12-classification.html#classification":{"body":0,"title":1,"breadcrumbs":3},"ml-concepts/ch01-16-multi-class-neural-nets.html#multi-class-neural-nets":{"breadcrumbs":6,"title":4,"body":0},"ml-concepts/ch01-11-logistic-regression.html#logistic-regression":{"title":2,"breadcrumbs":4,"body":0},"ml-concepts/ch01-05-generalization.html#peril-of-overfitting":{"breadcrumbs":4,"body":39,"title":2},"ml-concepts/ch00-00-ml-concepts.html#ml-concepts":{"body":0,"title":2,"breadcrumbs":2},"ml-concepts/ch01-03-reducing-loss.html#stochastic-gradient-descent":{"body":32,"breadcrumbs":5,"title":3},"ml-concepts/ch01-13-regularization-sparsity.html#regularization-sparsity":{"title":2,"breadcrumbs":4,"body":0},"ml-concepts/ch01-03-reducing-loss.html#an-iterative-approach":{"breadcrumbs":4,"title":2,"body":13},"appendix/a-cheat-sheet.html#a---cheat-sheet":{"breadcrumbs":3,"title":2,"body":0},"ml-concepts/ch01-03-reducing-loss.html#optimizing-learning-rate":{"title":3,"breadcrumbs":5,"body":4},"ml-concepts/ch01-06-training-and-test-sets.html#training-and-test-sets":{"title":3,"breadcrumbs":5,"body":0},"ml-concepts/ch01-07-validation.html#another-partition":{"title":2,"body":14,"breadcrumbs":4},"ml-concepts/ch01-03-reducing-loss.html#gradient-descent":{"body":17,"breadcrumbs":4,"title":2},"ml-concepts/ch01-03-reducing-loss.html#reducing-loss":{"body":0,"breadcrumbs":4,"title":2},"ml-concepts/ch01-03-reducing-loss.html#learning-rate":{"body":18,"breadcrumbs":4,"title":2},"ml-concepts/ch01-02-descending-into-ml.html#linear-regression":{"breadcrumbs":4,"title":2,"body":21},"ml-concepts/ch01-02-descending-into-ml.html#training-and-loss":{"breadcrumbs":4,"title":2,"body":28},"appendix/a-cheat-sheet.html#terminology-tensorflow-specific":{"body":13,"breadcrumbs":4,"title":3},"ml-concepts/ch01-07-validation.html#validation":{"body":0,"title":1,"breadcrumbs":3},"ml-concepts/ch01-08-representation.html#representation":{"breadcrumbs":3,"body":0,"title":1},"ml-concepts/ch01-04-first-steps-with-th.html#first-steps-with-tf":{"title":3,"body":0,"breadcrumbs":5},"ml-concepts/ch01-14-introduction-to-neural-nets.html#introduction-to-neural-nets":{"body":0,"breadcrumbs":5,"title":3},"appendix/appendix.html#appendix":{"title":1,"body":0,"breadcrumbs":1},"ml-concepts/ch00-00-ml-concepts.html#introduction-to-ml":{"body":8,"title":2,"breadcrumbs":2},"appendix/a-cheat-sheet.html#terminology":{"breadcrumbs":2,"body":57,"title":1},"ml-concepts/ch01-02-descending-into-ml.html#descending-into-ml":{"body":0,"breadcrumbs":4,"title":2},"ml-concepts/ch01-01-framing.html#ml-terminology":{"body":29,"title":2,"breadcrumbs":4},"ml-concepts/ch01-01-framing.html#framing":{"body":0,"title":1,"breadcrumbs":3},"ml-concepts/ch01-06-training-and-test-sets.html#splitting-data":{"breadcrumbs":4,"body":14,"title":2},"appendix/a-cheat-sheet.html#supervised-learning":{"title":2,"body":12,"breadcrumbs":3},"ml-concepts/ch01-10-regularization-simplicity.html#regularization-simplicity":{"body":0,"title":2,"breadcrumbs":4}},"length":37}}};